#  Cap铆tulo 1: El Panorama del Machine Learning

<br>

> *"Antes de tocar una sola l铆nea de c贸digo, debemos entender la arquitectura mental del ingeniero de ML."*

<br>
<br>

##  Objetivo del Cap铆tulo
Este m贸dulo establece los fundamentos te贸ricos cr铆ticos para distinguir entre la simple memorizaci贸n de datos y el verdadero aprendizaje autom谩tico generalizable. Aqu铆 diseccionamos los componentes que hacen que un sistema de ML sea robusto en producci贸n.

<br>
<br>

##  Conceptos Clave (Golden Nuggets)

<br>

### 1. Generalizaci贸n: 驴Memorizar o Entender?
Exploramos la diferencia fundamental entre:
* **Aprendizaje Basado en Instancias:** El modelo memoriza ejemplos (ej. k-NN).
* **Aprendizaje Basado en Modelos:** El modelo detecta patrones y construye una funci贸n matem谩tica (ej. Regresi贸n Lineal, Redes Neuronales).

<br>

### 2. Los "Asesinos Silenciosos" del Modelo
No basta con elegir un buen algoritmo; los datos suelen ser el culpable de los fallos.
* **Sampling Bias (Sesgo de Muestreo):** C贸mo datos no representativos pueden destruir la credibilidad de un modelo (Caso: Encuestas electorales fallidas).
* **Data Mismatch:** El peligro de entrenar con datos de alta calidad para un entorno de producci贸n de baja calidad.

<br>

### 3. Dise帽o Experimental Riguroso
La disciplina cient铆fica para evitar el auto-enga帽o.
* **Train / Validation / Test:** Por qu茅 dividir en dos partes no es suficiente.
* **Data Snooping:** C贸mo evitar "hacer trampa" inconscientemente al mirar demasiado el set de prueba.

---

<br>
<br>

##  Contenido T茅cnico

| Archivo | Descripci贸n |
| :--- | :--- |
| [**01_panorama_general.ipynb**](./01_panorama_general.ipynb) | **Notebook Principal.** Implementaci贸n de ejemplos de generalizaci贸n, visualizaci贸n de sesgos y configuraci贸n del entorno. |

---

##  Video Explicativo

Profundizo en estos conceptos y explico el c贸digo paso a paso en mi canal:

[ **Ver Video: Fundamentos de ML y el Arte de la Generalizaci贸n**](LINK_A_TU_VIDEO_AQUI)
